---
title: "l1svr: An R Package for Support Vector Regression under l1 Regularization"
author: "Yuehao Bai, Hung Ho, Guillaume Pouliot, and Joshua Shea"
bibliography: l1svr.bib
output:
  github_document:
    toc: true
    keep_html: true
  html_document:
    toc: true
    keep_md: true
vignette: >
  %\VignetteIndexEntry{l1svr}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE,
  fig.path = "vignettes/l1svr_files/figure-gfm/"
)
require(pander)
require(ggplot2)
require(l1svr)
```

## Introduction

The **l1svr** package allows the user to estimate and perform statistical inference for support vector regressions under l1 regularization (l1-SVR).
This vignette documents package installation and requirements, and demonstrates how the package may be used.
We refer the reader to @bai2021inference for technical details on how the estimation and inference are carried out.

## Installation and Requirements

<!-- **l1svr** can be installed from CRAN via -->
<!-- ```{r eval = FALSE} -->
<!-- install.packages("l1svr") -->
<!-- ``` -->

The latest version of the module may be installed from our GitHub repository using the **devtools** package.

```{r eval = FALSE}
devtools::install_github("jkcshea/l1svr")
```

A package for solving linear programs is required.
The user can choose from three options.

1. Gurobi and the Gurobi R package **gurobi**, which can be obtained from [Gurobi Optimization](http://www.gurobi.com/index).
   This option requires a Gurobi software license, which Gurobi Optimization offers at no cost to academic researchers.
   
2. CPLEX and the package **cplexAPI**,  which is available on CRAN.
   CPLEX can be obtained from [IBM](https://www.ibm.com/analytics/cplex-optimizer).
   This option requires a software license, which IBM offers at no cost to academic researchers.
   
3. The **lpSolveAPI** package, which is free and open-source, and available from CRAN.
   Note that **lpSolveAPI** is a wrapper for [lp_solve](http://lpsolve.sourceforge.net/5.5/), which is no longer actively developed.

We _strongly_ recommend using Gurobi or CPLEX, since these are actively developed, much more stable, and typically an order of magnitude faster than **lpSolveAPI**.
A very clear installation guide for Gurobi can be found [here](https://cran.r-project.org/package=prioritizr/vignettes/gurobi_installation.html)

The package includes the data set `simdata`, which we will use to demonstrate the features of the package.

```{r, show-data}
library(l1svr)
knitr::kable(head(simdata))
```

### Basic estimation and inference

In support vector regressions, the parameters of a linear regression model are estimated by minimizing a loss function that linearly penalizes the errors exceeding a threshold `epsilon`, as depicted in the figure below.

```{r, loss, eval = TRUE, echo = FALSE, fig.align = 'center', fig.width = 7,fig.height = 3}
  library(ggplot2)
  lossFunc <- function(x, epsilon) {
      return(max(c(abs(x) - epsilon, 0)))
  }
  lossFunc <- Vectorize(lossFunc, 'x')
  epsilon <- 0.5
  xseq <- seq(-2, 2, 0.5)
  yseq <- lossFunc(xseq, epsilon)
  ggplot() +
      geom_line(mapping = aes(x = xseq,
                              y = yseq)) +
      scale_x_continuous(breaks = c(seq(min(xseq), max(xseq), 1),
                                    -epsilon, epsilon),
                         labels = c(seq(min(xseq), max(xseq), 1),
                                    expression(-epsilon), expression(epsilon)),
                         limits = c(min(xseq), max(xseq))) +
      scale_y_continuous(limits = c(0, max(yseq)),
                         breaks = seq(0, max(yseq), 0.5)) +
      labs(x = 'Error',
           y = 'Loss') +
      theme(panel.background = element_blank(),
            axis.line = element_line(),
            axis.text = element_text(size = 14))
```

The l1-norm regularization includes an additional penalty proportional to the l1-norm of the coefficient estimates.
The extent of the regularization is controlled by the tuning parameter `lambda`, which scales the l1-penalty on the coefficient estimates.

To estimate a linear regression model using the **l1svr** package, the user must pass a data set, a regression equation, a bandwidth `epsilon`, and a tuning parameter `lambda` to the function `l1svr`.
The user may also choose which solver to use by setting the `solver` argument to `'gurobi'`, `'cplexapi'`, or `'lpsolveapi'`. 
By default, `solver = 'gurobi'`.

```{r, basic-demo}
fit1 <- l1svr(formula = y ~ 1 + x1 + x2,
              data = simdata,
              epsilon = 7,
              lambda = 20,
              solver = 'gurobi')
summary(fit1)
```

The coefficient estimates are stored in the entry `$coefficients` of the output, and the p-values are stored in the entry `$pvalues`.
By default, statistical inference is performed assuming that the errors are homoskedastic.

Inference under heteroskedasticity is also possible, but requires the density of the errors to be estimated.
To enable this feature, the user must provide the additional tuning parameters needed for density estimation.
The **l1svr** package estimates the density of the errors using the procedure described in @powell1991estimation, which involves two positive  scalar tuning parameters, `h` and `kappa`.
They determine the bandwidth used for density estimation, and the bandwidth is increasing in both parameters. 
The parameter `h` determines the quantiles of a standard normal distribution used to define the bandwidth, and the parameter `kappa` directly scales the bandwidth.
Inference under heteroskedasticity will not be performed unless both `h` and `kappa` are passed.
We refer the reader to the Online Appendix of @bai2021inference for additional details on how inference is performed under heteroskedasticity.

```{r, hetero-demo}
fit2 <- l1svr(formula = y ~ 1 + x1 + x2,
              data = simdata,
              epsilon = 7,
              lambda = 20,
              h = 2,
              kappa = 1.75)
summary(fit2)
```

If desired, the user may turn off the inference procedure by setting `inference = FALSE`.

### Constructing confidence intervals

The `l1svr` function is able to construct confidence intervals by inverting the test procedure.
This entails the function implementing the l1-SVR regression rankscore test under a sequence of null hypotheses for each coefficient estimate.
The end points of the confidence interval correspond to the null hypotheses under which the p-value of the test statistic is equal to the size of the test, up to some tolerance.
This is a computationally intensive procedure and is disabled by default.

To enable the estimation of confidence intervals, set the argument `confidence.level` to a value between 0 and 1.
As its name indicates, this argument also determines the confidence level of the intervals.
The iterative procedure will terminate when the difference between the p-value of the endpoints of the confidence interval and the size of the test (`1 - confidence.level`) is within the level of tolerance.
By default, the tolerance is equal to `1e-3`, but can be adjusted using the argument `confidence.tol`.
The maximum number of iterations performed may also be set using `confidence.iter`.
In the example below, the confidence intervals are constructed assuming that the errors are homoskedastic.

```{r, ci-demo}
fit3 <- l1svr(formula = y ~ 1 + x1 + x2,
              data = simdata,
              epsilon = 7,
              lambda = 20,
              confidence.level = 0.95,
              confidence.iter = 20,
              confidence.tol = 2e-3)
summary(fit3)
```


In the example above, the user is informed that the estimation of some of the confidence intervals has been terminated before the p-value at the endpoints are within tolerance to the size of the test since the iteration limit was reached.
The estimated confidence interval may therefore not reflect the confidence level set by the user.
In addition to warning the user of these instances, the function returns the p-values at the end points of each confidence interval in the entry `$ci` of the output, along with details on the iterative procedure.

```{r, full-ci-output}
fit3$ci
```

Another reason that the estimation of confidence intervals may terminate prematurely is that the estimated endpoints across successive iterations have become sufficiently small.
This implies that the solver is unable to perform the test at the level of precision required for the p-value of the bound to fall within tolerance to the size of the test.
The user can try to avoid this by reducing `confidence.same`, which sets the tolerance level determining whether two bounds from successive iterations of the procedure are sufficiently close.
By default, this parameter is equal to `1e-06`.
However, since the limitation pertains to the solver, there is no guarantee that reducing this parameter will improve the estimate of the confidence intervals.

## Help, Feature Requests and Bug Reports

Please post an issue on the [GitHub repository](https://github.com/jkcshea/l1svr/issues).

## References
